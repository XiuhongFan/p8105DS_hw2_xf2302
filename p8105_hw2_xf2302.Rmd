---
title: "p8105_hw2_xf2302"
output: github_document
date: "2025-09-30"
---
# Problem 1
```{r}
library(tidyverse)
```
# Clean pols-month.csv dataset
```{r}
pols <- 
  read_csv("data/pols-month.csv") |> 
  separate(mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    month = month.name[month],
    president = if_else(prez_gop == 1, "gop", "dem")
  ) |> 
  select(-day, -prez_gop, -prez_dem)
```
# 2. Clean snp.csv dataset
```{r}
snp <- 
  read_csv("data/snp.csv") |> 
  separate(date, into = c("month", "day", "year"), sep = "/") |> 
  mutate(
    month = as.integer(month),
    year = as.integer(year),
    year = if_else(year < 100,            
                   if_else(year >= 50, 1900 + year, 2000 + year),
                   year),
    month = month.name[month]
  ) |> 
  select(year, month, close) |> 
  arrange(year, month)
```
# 3. Clean unemployment.csv
```{r}
unemployment <- 
  read_csv("data/unemployment.csv") |> 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment"
  ) |> 
  mutate(
    year = as.integer(Year),
    month = month.name[match(month, month.abb)]
  ) |> 
  select(year, month, unemployment)
```
# 4. Merge datasets and inspect merged dataset
```{r}
merged_data <- 
  pols |> 
  left_join(snp, by = c("year", "month")) |> 
  left_join(unemployment, by = c("year", "month"))
dim(merged_data)        
range(merged_data$year) 
head(merged_data)       
```
The **FiveThirtyEight datasets** combine information on U.S. politics, the stock market, and unemployment. 
The `pols-month.csv` dataset contains monthly counts of national politicians (governors, senators, and representatives) 
by political party, from `r min(pols$year)` to `r max(pols$year)`. 

The `snp.csv` dataset records monthly closing values of the S&P 500 index, ranging from `r min(snp$year)` to `r max(snp$year)`. 
The `unemployment.csv` dataset provides national unemployment rates, reported monthly from `r min(unemployment$year)` to `r max(unemployment$year)`.  

After cleaning and merging these datasets by year and month, the resulting dataset has **`r nrow(merged_data)` rows** 
and **`r ncol(merged_data)` variables**, covering the period **`r min(merged_data$year)`–`r max(merged_data$year)`**. 
Key variables include the counts of politicians by party, the sitting president’s party, monthly unemployment rates, 
and the S&P 500 closing values. Note that missing values occur where data are not available 
(e.g., stock market values before `r min(snp$year)`, unemployment data in `r min(unemployment$year)-1`).

# Problem 2
```{r}
library(readxl)
library(dplyr)
library(janitor)
```

# Define a Cleaning Function
```{r}
clean_trash <- function(sheet_name, wheel_name) {
  df <- read_excel(
    "data/202509 Trash Wheel Collection Data.xlsx",
    sheet = sheet_name,
    skip = 1
  ) |>
    clean_names() |> 
    filter(!is.na(dumpster)) |>          
    select(-starts_with("...")) |> 
    mutate(
      year = as.integer(year)   
    )
  
  if ("sports_balls" %in% colnames(df)) {
    df <- df |>
      mutate(sports_balls = as.integer(round(sports_balls, 0)))
  } else {
    df <- df |>
      mutate(sports_balls = NA_integer_)
  }
  df |>
    mutate(wheel = wheel_name)
}
```
# Clean Each Trash Wheel Dataset and combine Datasets
```{r}
mr_trash   <- clean_trash("Mr. Trash Wheel", "Mr. Trash Wheel")
prof_trash <- clean_trash("Professor Trash Wheel", "Professor Trash Wheel")
gwynnda    <- clean_trash("Gwynns Falls Trash Wheel", "Gwynnda")
all_trash <- bind_rows(mr_trash, prof_trash, gwynnda)
```
# Compute Results
```{r}
n_obs <- nrow(all_trash)
prof_total_weight <- sum(prof_trash$weight_tons, na.rm = TRUE)
gwynnda_cig_2022_06 <- gwynnda |>
  filter(year == 2022, month == "June") |>
  summarise(total_cig = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(total_cig)
n_obs
prof_total_weight
gwynnda_cig_2022_06
```

The combined Trash Wheel dataset contains `r n_obs` observations.  
Professor Trash Wheel collected a total of `r round(prof_total_weight, 2)` tons of trash.  
In June 2022, Gwynnda collected `r format(gwynnda_cig_2022_06, big.mark = ",")` cigarette butts.
Key variables include dumpster ID, collection date, total weight (in tons), counts of plastic bottles, polystyrene, cigarette butts, and sports balls.  

# Problem 3
```{r}
library(readr)
library(dplyr)
library(tidyr)
library(janitor)
```

# Load and clean Zip Codes and ZORI data
```{r}
zips <- read_csv("data/Zip Codes.csv") %>% 
  clean_names()

zori <- read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") %>% 
  clean_names()
```
# Tidy ZORI data
```{r}
zori_tidy <- zori %>% 
  pivot_longer(
    cols = starts_with("x"),       
    names_to = "month",
    values_to = "rent_index"
  ) %>% 
  mutate(
    month = gsub("^x", "", month),                 
    month = as.Date(month, format = "%Y_%m_%d")    
  )
```
# Deduplicate ZIPs
```{r}
zips_unique <- zips %>% distinct(zip_code, .keep_all = TRUE)
```
# Join ZORI + ZIP
```{r}
zori_final <- zori_tidy %>%
  left_join(zips_unique, by = c("region_name" = "zip_code")) %>%
  arrange(region_name, month)
```
# Compute stats
```{r}
n_obs <- nrow(zori_final)                                 
n_zip <- n_distinct(zori_final$region_name)               
n_neighborhood <- n_distinct(zori_final$neighborhood)     
```
# Find missing ZIPs
```{r}
missing_zips <- setdiff(zips_unique$zip_code, zori$region_name)
```
# Compare 2020 vs 2021
```{r}
zori_compare <- zori_final %>%
  filter(month %in% as.Date(c("2020-01-31", "2021-01-31"))) %>%
  select(region_name, county, neighborhood, month, rent_index) %>%  
  pivot_wider(
    names_from = month,
    values_from = rent_index,
    names_prefix = "rent_"
  ) %>%
  mutate(drop = `rent_2021-01-31` - `rent_2020-01-31`) %>%  
  arrange(drop) %>%
  slice_head(n = 10)
```
# Output results
```{r}
n_obs
n_zip
n_neighborhood
missing_zips
zori_compare
```
A single tidy dataset was created by combining ZIP code–level information with Zillow’s ZORI data from January 2015 to August 2024. After cleaning and merging, the dataset contained `r n_obs` observations, representing `r n_zip` unique ZIP codes across `r n_neighborhood` neighborhoods in New York City. Several ZIP codes listed in the ZIP code dataset did not appear in the Zillow rental dataset (e.g., `r paste(head(missing_zips, 5), collapse = ", ")`). Many of these excluded ZIP codes correspond to special-purpose areas such as commercial districts, large institutions, or PO boxes, which do not have sufficient rental market activity to be represented in Zillow’s database.  

Rental prices shifted dramatically during the COVID-19 pandemic. When comparing January 2020 to January 2021, the ten ZIP codes with the largest price declines were identified. These were concentrated in Manhattan, particularly in neighborhoods such as Lower Manhattan, the East Village, Gramercy Park, Chelsea, and Greenwich Village.  

The table below presents the ZIP codes with the steepest rental price drops:  

`r knitr::kable(zori_compare, digits = 0)`  

Overall, the analysis confirms that Manhattan’s core rental markets experienced the most severe downturns during the pandemic, with typical declines of 600–900 USD per month, while rental markets in the outer boroughs were less severely affected.


